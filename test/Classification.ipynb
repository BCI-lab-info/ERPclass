{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "* Roadmap\n",
    "    * Signal (Put all subjects together)\n",
    "        * all channel\n",
    "            * no filter\n",
    "            * low pass\n",
    "        * averaged signal\n",
    "            * no filter\n",
    "            * low pass\n",
    "    * Algorithm\n",
    "        * Linear Model: Logistic Regression, SVM, PA\n",
    "        * Nonlinear Model: SVM (RBF kernel)\n",
    "        * Neural Network\n",
    "\n",
    "\n",
    "* ***WARNING [order of the feature > sample size] ***\n",
    "    * large epoch\n",
    "    * down sampliing (FIR filter)\n",
    "    * averaging 16 channels -> 1 channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "audio = glob.glob(\"../data/sample1/audio/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions import filtering\n",
    "\n",
    "def extract_array(path):\n",
    "    \"\"\" Since the experiment data is\n",
    "    tuple with its string 'tag' such as\n",
    "        - label: ('label', ndarray)\n",
    "        - eeg: ('eeg', ndarray)\n",
    "    extract only ndarray and return them.\n",
    "    \"\"\"\n",
    "\n",
    "    label, eeg = np.load(path).items()\n",
    "    return label[1], eeg[1]\n",
    "\n",
    "def combine_data(path):\n",
    "    # initialize\n",
    "    data = None\n",
    "    for p in path:\n",
    "        label, eeg = extract_array(p)\n",
    "        if data is None:\n",
    "            labels, data = label, eeg\n",
    "        else:\n",
    "            data = np.concatenate((data, eeg), axis=0)\n",
    "            labels = np.hstack([labels, label])\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "class ParseData(object):\n",
    "    \"\"\"Preprocess target data\n",
    "\n",
    "    - Put all subjects together\n",
    "    - Split them into 'train' and 'test'\n",
    "\n",
    "     Parameter\n",
    "    --------------------------\n",
    "    data_paths: list of paths of experiment data\n",
    "    \n",
    "     Attribute\n",
    "    --------------------------\n",
    "    train_data: eeg signal of train data\n",
    "    train_label: labels of train data\n",
    "    test_data: eeg signal of test data\n",
    "    test_label: labels of test data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_paths):\n",
    "        train_data, train_label, test_data, test_label \\\n",
    "            = self.__parse(data_paths)\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.train_label = train_label\n",
    "        self.test_data = test_data\n",
    "        self.test_label = test_label\n",
    "    \n",
    "    def __parse(self, data_paths):\n",
    "        # split 'test' and 'train'\n",
    "        path_test = []\n",
    "        path_train = []\n",
    "        for d_ in data_paths:\n",
    "            if 'test' in d_:\n",
    "                path_test.append(d_)\n",
    "            elif 'train' in d_:\n",
    "                path_train.append(d_)\n",
    "        # modify\n",
    "        train_data, train_label = combine_data(path_train)\n",
    "        test_data, test_label = combine_data(path_test)\n",
    "        return train_data, train_label, test_data, test_label\n",
    "    \n",
    "#     def filtering(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = ParseData(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(Data):\n",
    "    # Frequency\n",
    "    fs = 512\n",
    "    # Nyquist frequency\n",
    "    nyq = fs / 2.0  \n",
    "    # Cut off frequency\n",
    "    fil = \"l\"\n",
    "    cut_low = 1/10*nyq\n",
    "\n",
    "    inputs = None\n",
    "    for data in Data:\n",
    "        data = data.mean(0)\n",
    "        data = filtering(fil, data, nyq=nyq, cut_low=cut_low,\n",
    "                         numtaps=225, sampling_rate=2, ignore=100)\n",
    "        if inputs is None:\n",
    "            inputs = data\n",
    "        else:\n",
    "            inputs = np.vstack([inputs, data])\n",
    "    return inputs\n",
    "\n",
    "X_1 = data(signals.test_data)\n",
    "X_2 = data(signals.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_1 = signals.test_label\n",
    "y_2 = signals.train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (8250, 257) (4000, 257)\n",
      "Label: (8250,) (4000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data:\", X_1.shape, X_2.shape)\n",
    "print(\"Label:\", y_1.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1, y_1 = shuffle(X_1, y_1, random_state=0)\n",
    "X_2, y_2 = shuffle(X_2, y_2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-13341b41afc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "clf = {\n",
    "    \"log\": LogisticRegression(),\n",
    "    \"svm\": SVC(),\n",
    "}\n",
    "for clf_ in clf:\n",
    "    print(clf_)\n",
    "    \n",
    "    clf_.fit(X_1, y_1)\n",
    "    print(clf.score(X_2, y_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)), ('log', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.items()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
